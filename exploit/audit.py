# File: audit.py
# This file audits chatbot responses and prompts for potential confidential leaks or system refusals

from openai import OpenAI
from utils.config import OPENAI_API_KEY, LEAK_CHECKER_PROMPT, ATTACK_CHECKER_PROMPT
from utils.chat_context import ChatMessageBuilder
import json

# Audits prompts and responses 
class Audit:

    # Inject openai client
    def __init__(self, client=None):
        self.client = client or OpenAI(api_key=OPENAI_API_KEY)

    # Audits a response to see if a leak occurred
    def leak(self, bot_type: str, final_response: str, context: list, model: str = "gpt-4") -> bool:
        # Initialize the message builder with system prompt and context
        builder = ChatMessageBuilder(system_prompt=LEAK_CHECKER_PROMPT, context_entries=context)
        
        # Prepend metadata about the simulation
        builder.prepend_message("user", f"bot_type: {bot_type}")
        builder.append_message("user", f"Final Response: {final_response}")
        
        # Render everything as combined user messages
        messages = builder.build_messages(
            mode="combined_user",
            template="Prompt: {prompt} Response: {response}"
        )

        # Audit for leak
        result = self.client.chat.completions.create(
            model=model,
            messages=messages
        )

        try:
            parsed = json.loads(result.choices[0].message.content)
            return parsed.get("leaked", False)
        except Exception as e:
            print(f"[ERROR] Parsing model response: {e}")
            return False

    # Checks if a message is a valid attack prompt
    def attack(self, message: str, model: str = "gpt-4") -> bool:
        # Initialize the message builder with system prompt and context
        builder = ChatMessageBuilder(system_prompt=ATTACK_CHECKER_PROMPT)

        # Prepend metadata about the simulation
        builder.append_message("user", message)
        
        # Render everything as combined user messages
        messages = builder.as_user_assistant()
        
        # Audit attack prompt
        result = self.client.chat.completions.create(
            model=model,
            messages=messages
        )

        try:
            parsed = json.loads(result.choices[0].message.content)
            return parsed.get("valid_attack", False)
        except Exception as e:
            print(f"[ERROR] Parsing model response: {e}")
            return False
