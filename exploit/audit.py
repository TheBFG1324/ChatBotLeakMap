# File: audit.py
# This file audits chatbot responses for potential confidential leaks or system refusals

from openai import OpenAI
from utils.config import OPENAI_API_KEY, LEAK_CHECKER_PROMPT, ATTACK_CHECKER_PROMPT
import json

# Validates whether a leak of confidential information occurred or a system refusal hasn't occurred
class Audit:

    # Inject openai client
    def __init__(self, client=None):
        self.client = client or OpenAI(api_key=OPENAI_API_KEY)

    # Audits a response to see if a leak occurred
    def leak(self, bot_type: str, final_response: str, context: list, model: str = "gpt-4") -> bool:
        system_prompt = LEAK_CHECKER_PROMPT

        messages = [{"role": "system", "content": system_prompt}]
        messages.append({"role": "user", "content": f"bot_type: {bot_type}"})

        for entry in sorted(context, key=lambda x: x["message_number"]):
            messages.append({"role": "user", "content": f"Prompt: {entry['prompt']} Response: {entry['response']}"})

        messages.append({"role": "user", "content": f"Final Response: {final_response}"})

        result = self.client.chat.completions.create(
            model=model,
            messages=messages
        )

        try:
            content = result.choices[0].message.content
            parsed = json.loads(content)
            return parsed.get("leaked", False)
        except Exception as e:
            print(f"[ERROR] Parsing model response: {e}")
            return False

    # Checks if a message is a valid attack prompt
    def attack(self, message: str, model: str = "gpt-4") -> bool:
        system_prompt = ATTACK_CHECKER_PROMPT

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ]

        result = self.client.chat.completions.create(
            model=model,
            messages=messages
        )

        try:
            content = result.choices[0].message.content
            parsed = json.loads(content)
            return parsed.get("valid_attack", False)
        except Exception as e:
            print(f"[ERROR] Parsing model response: {e}")
            return False

