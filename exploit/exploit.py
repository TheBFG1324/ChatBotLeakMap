# File: exploit.py
# This file holds the main functionality to crawl, discover, classify, and exploit chatbots to reveal sensitive information

# Import needed packages
import uuid
import random
import datetime
import requests

from crawler.crawler import ChatbotCrawler
from exploit.exploiter import Exploiter
from exploit.audit import Audit
from db.neo4j_driver import Neo4jDriver
from db.embed import get_embedding


# Exploit chatbots
class Exploit:
    def __init__(self, urls: list[str], temperature: float = 0.5, max_iterations: int = 10, threshold: float = 0.7):
        self.urls = urls
        self.temperature = temperature
        self.max_iterations = max_iterations
        self.threshold = threshold

    # Start a prompt attack against the given urls
    def prompt_attack(self) -> list[dict]:
        results: list[dict] = []
        crawler = ChatbotCrawler(self.urls)
        exploiter = Exploiter()
        audit = Audit()
        driver = Neo4jDriver()

        try:
            bots = crawler.discover_and_register()
            print("Bots: ")
            print(bots)

            for bot in bots:
                domain = bot["domain"]
                if domain == "unknown":
                    continue
                print("Bot: ")
                print(bot)
                bot_id = str(uuid.uuid4())
                chain_id = str(uuid.uuid4())
                timestamp = datetime.datetime.now().isoformat()

                # Register bot and chain in Neo4j
                driver.insert_bot(bot_id=bot_id, name=bot["bot_name"], type_=domain, url=bot["api_url"])
                driver.create_chain(
                    chain_id=chain_id,
                    bot_id=bot_id,
                    timestamp=timestamp,
                    temperature=self.temperature,
                    mode=self._initial_mode()
                )

                # Initialize attack context
                context: list[dict] = []
                prev_resp: str | None = None
                suggested_prompt: str | None = None
                mode = self._initial_mode()

                # Run attack iterations
                for iteration in range(self.max_iterations):
                    print(f"Mode: {mode}")
                    print(f"Suggested Prompt: {suggested_prompt}")
                    prompt = exploiter.create_prompt(
                        bot_type=domain,
                        context=context,
                        suggestive_prompt=suggested_prompt,
                        mode=mode,
                        previous_response=prev_resp,
                        max_iterations=self.max_iterations
                    )
                    print(f"Attack Prompt: {prompt}, iteration: {iteration}")
                    prompt_id = driver.get_or_create_prompt(
                        prompt_id=str(uuid.uuid4()),
                        text=prompt
                    )

                    # Send prompt to bot
                    response_text = self.send_prompt(bot["api_url"], prompt)
                    if response_text is None:
                        break
                    
                    print(f"Response: {response_text}")
                    # Persist response and compute embedding
                    embedding = get_embedding(text=response_text)
                    response_id = driver.get_or_create_response(
                        response_id=str(uuid.uuid4()),
                        text=response_text,
                        timestamp=timestamp,
                        embedding=embedding
                    )

                    print("Linking....")
                    # Link the prompt and response in the graph
                    driver.link_step(chain_id=chain_id, prompt_id=prompt_id, step_number=iteration)
                    driver.link_result(prompt_id=prompt_id, response_id=response_id)
                    print("successfully linked.")

                    # Audit for leaks
                    print("Checking for leak...")
                    if audit.leak(bot_type=domain, final_response=response_text, context=context):
                        print("Leak detected!")
                        driver.mark_chain_success(chain_id=chain_id, response_id=response_id)
                        break
                    print("Leak not detected.")

                    # Update context for next iteration
                    context.append({
                        "message_number": iteration,
                        "prompt": prompt,
                        "response": response_text
                    })

                    prev_resp = response_text
                    best_match = driver.find_best_match(
                        embedding=embedding,
                        threshold=self.threshold,
                        bot_type=domain
                    )

                    suggested_prompt = best_match.get("prompt_text") if best_match else None
                    mode = self.get_mode()

                results.append({"bot_id": bot_id, "chain_id": chain_id})

                print("----------------------------")
        finally:
            driver.close()

        return results

    # Initial mode for the exploiter
    def _initial_mode(self) -> str:
        return "explorative"

    # Gets the mode for the exploiter based on the temperature
    def get_mode(self) -> str:
        return "explorative" if random.random() < self.temperature else "exploitative"

    # Sends a given message to the desired chatbot
    def send_prompt(self, url: str, message: str) -> str:
        try:
            resp = requests.post(url, json={"message": message}, timeout=10)
            resp.raise_for_status()
            return resp.json().get("response")
        except requests.exceptions.RequestException as e:
            return None


if __name__ == "__main__":
    # 2) Define the URLs you want to test against
    urls = [
        "http://localhost:5010"
    ]

    # 3) Instantiate and run
    expl = Exploit(
        urls=urls,
        temperature=0.6,
        max_iterations=5,
        threshold=0.8
    )
    results = expl.prompt_attack()

    # 4) Print a summary at the end
    print("\n=== Attack Summary ===")
    for r in results:
        print(f" • Bot {r['bot_id']}  →  Chain {r['chain_id']}")

