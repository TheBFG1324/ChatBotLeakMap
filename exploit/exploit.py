# File: exploit.py
# Main module to crawl, classify, and exploit chatbots to reveal sensitive information

import uuid
import random
import datetime
import requests

from crawler.crawler import ChatbotCrawler
from exploit.exploiter import Exploiter
from exploit.audit import Audit
from db.neo4j_driver import Neo4jDriver
from db.embed import get_embedding


class Exploit:
    def __init__(
        self,
        urls: list[str],
        *,
        temperature:    float             = 0.5,
        max_iterations: int               = 10,
        threshold:      float             = 0.5,
        timeout:        float             = 30.0,
        crawler:        ChatbotCrawler,
        exploiter:      Exploiter,
        audit:          Audit,
        driver:         Neo4jDriver,
    ) -> None:
        
        # core config
        self.urls = urls
        self.temperature = temperature
        self.max_iterations = max_iterations
        self.threshold = threshold
        self.timeout = timeout
        
        # injected collaborators
        self.crawler = crawler
        self.exploiter = exploiter
        self.audit = audit
        self.driver = driver

    # Launch prompt injection attacks against discovered bots
    def prompt_attack(self) -> list[dict]:
        results: list[dict] = []
        crawler = self.crawler
        exploiter = self.exploiter
        audit = self.audit
        driver = self.driver

        try:
            # Crawl and discover chatbots
            print("======= Crawling Sites =======")
            print(f"Searching for and classifying bots at: {self.urls}")
            bots = crawler.discover_and_register()
            print("Bots have been discovered.")
            print("================================\n")

            for bot in bots:
                domain = bot["domain"]
                if domain == "unknown":
                    continue

                print(f"Discovered Bot: {bot}\n")

                bot_id = str(uuid.uuid4())
                chain_id = str(uuid.uuid4())
                timestamp = datetime.datetime.now().isoformat()

                # Register bot and prompt chain in Neo4j
                driver.insert_bot(bot_id=bot_id, name=bot["bot_name"], type_=domain, url=bot["api_url"])
                driver.create_chain(
                    chain_id=chain_id,
                    bot_id=bot_id,
                    timestamp=timestamp,
                    temperature=self.temperature,
                    mode=self._initial_mode()
                )

                print(f"Prompt Injection Chain Created: {chain_id}\n")
                print("======= Starting Prompt Injection Attack =======")
                print(f"Attack Temperature: {self.temperature}, Max Iterations: {self.max_iterations}, Embedding Threshold: {self.threshold}\n")

                # Load prompt injection attack context
                context: list[dict] = []
                prev_resp: str | None = None
                suggested_prompt: str | None = None
                suggested_prompt_id: str | None = None
                mode = self._initial_mode()

                for iteration in range(self.max_iterations):
                    print(f"Iteration: {iteration} | Mode: {mode}\n")

                    # Create the next prompt injection attack in the chain
                    prompt = exploiter.create_prompt(
                        bot_type=domain,
                        context=context,
                        suggestive_prompt=suggested_prompt,
                        mode=mode,
                        previous_response=prev_resp,
                        max_iterations=self.max_iterations
                    )

                    print(f"Attack Prompt: {prompt}\n")

                    # Store prompt information in db
                    prompt_id = driver.get_or_create_prompt(
                        prompt_id=str(uuid.uuid4()),
                        text=prompt
                    )

                    # Store prompt references if used
                    if mode == "exploitative":
                        print(f"Referencing Previous Prompt {suggested_prompt_id}\n")
                        driver.link_reference(prompt_id=prompt_id, referenced_prompt_id=suggested_prompt_id)

                    # Send prompt injection to targeted chatbot
                    response_text = self.send_prompt(bot["api_url"], prompt)
                    if response_text is None:
                        break

                    print(f"Response: {response_text}\n")

                    # Store the response data and embedding in db
                    embedding = get_embedding(text=response_text)
                    response_id = driver.get_or_create_response(
                        response_id=str(uuid.uuid4()),
                        text=response_text,
                        timestamp=timestamp,
                        embedding=embedding
                    )

                    # Link steps in attack chain
                    print("Linking Data to Neo4j Database...")
                    driver.link_step(chain_id=chain_id, prompt_id=prompt_id, step_number=iteration)
                    driver.link_result(prompt_id=prompt_id, response_id=response_id)
                    print("Successfully Linked.\n")
                    
                    # Check response for confidential information
                    print("Checking for leak...")
                    if audit.leak(bot_type=domain, final_response=response_text, context=context):
                        print("Leak detected!\n")
                        driver.mark_chain_success(chain_id=chain_id, response_id=response_id)
                        break
                    print("Leak not detected.\n")

                    # Append chat context
                    context.append({
                        "message_number": iteration,
                        "prompt": prompt,
                        "response": response_text
                    })

                    # Load suggested next best prompt/s from Neo4j
                    prev_resp = response_text
                    best_next_prompt = driver.suggested_next_prompt(
                        embedding=embedding,
                        threshold=self.threshold,
                        bot_type=domain
                    )

                    suggested_prompt = best_next_prompt.get("prompt_text") if best_next_prompt else None
                    suggested_prompt_id = best_next_prompt.get("prompt_id") if best_next_prompt else None
                    mode = self.get_mode()

                results.append({"bot_id": bot_id, "chain_id": chain_id})
                print("================================\n")

        finally:
            driver.close()

        return results

    # Returns initial mode for attack
    def _initial_mode(self) -> str:
        return "explorative"

    # Returns next mode for attack based on temperature
    def get_mode(self) -> str:
        return "explorative" if random.random() < self.temperature else "exploitative"

    # Send prompt injection attack to chatbot
    def send_prompt(self, url: str, message: str) -> str:
        try:
            resp = requests.post(url, json={"message": message}, timeout=self.timeout)
            resp.raise_for_status()
            return resp.json().get("response")
        except requests.exceptions.RequestException:
            return None
